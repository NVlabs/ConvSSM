seed: 1
cache: false # caching available only for encoded datasets

# Training
multinode: False
batch_size: 8
eval_size: 1024
num_workers: 4
lr: 0.0005
lr_schedule: "cosine"
weight_decay: 0.00001
total_steps: 300000
warmup_steps: 5000
save_interval: 50000
viz_interval: 50000
log_interval: 100

# Data
data_path: "/raid/moving_mnist_long_1"
eval_seq_len_1: 500
eval_seq_len_2: 1000
seq_len: 300
image_size: 64
channels: 1

num_shards: null
rng_keys: ["dropout", "sample"]
batch_keys: ["video", "actions"]

# Model
model: "transformer_noVQ"

loss_weight: 0.5

encoder: # encoder / decoder are mirrored, with decoder depths reversed
  depths: [64, 128, 256] # 64x64 to 16x16
  blocks: 1

decoder: # encoder / decoder are mirrored, with decoder depths reversed
  depths: [64, 128, 256] # 16x16 to 64x64
  blocks: 1

latent_shape: [16, 16]
z_ds: 16 # 16x16 -> 1x1
z_tfm_kwargs:
  embed_dim: 1024
  mlp_dim: 4096
  num_heads: 16
  num_layers: 8
  dropout: 0.
  attention_dropout: 0.

embedding_dim: 256
n_cond: 1
drop_loss_rate: 0.0

causal_masking: False

# Actions
use_actions: False
action_dim: 1
action_embed_dim: 1
dropout_actions: False
action_dropout_rate: 0.0
action_mask_id: -1

# Sampling
open_loop_ctx: 100

open_loop_ctx_1: 100
action_conditioned_1: False
open_loop_ctx_2: 100
action_conditioned_2: False
